{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef0bed0",
   "metadata": {},
   "source": [
    "# Complexity Metric Problematization - Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e41ee97",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pm4py.objects.log.obj import Event, EventLog, Trace\n",
    "\n",
    "from complexity_sample_size_correlation_analysis import (\n",
    "    compute_metrics_for_samples, sample_random_traces_with_replacement)\n",
    "\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.objects.conversion.bpmn import converter as bpmn_converter\n",
    "from pm4py.algo.simulation.playout.petri_net import algorithm as simulator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae5cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers\n",
    "def make_trace(variant, trace_id: int):\n",
    "    # give each trace a unique name/id\n",
    "    trace = Trace(attributes={\"concept:name\": f\"Case{trace_id}\"})\n",
    "    # add events with both concept:name and timestamp\n",
    "    base_time = datetime.datetime(2020, 1, 1, 0, 0, 0)  # arbitrary starting point\n",
    "    for i, act in enumerate(variant):\n",
    "        event = Event({\n",
    "            \"concept:name\": act,\n",
    "            \"time:timestamp\": base_time + datetime.timedelta(minutes=i)\n",
    "        })\n",
    "        trace.append(event)\n",
    "    return trace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd412ea6",
   "metadata": {},
   "source": [
    "## P1 Strict Monotone growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1503b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_metrics_per_log = {}\n",
    "\n",
    "# Create a trace variant A-B-C-D-E\n",
    "variant = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "\n",
    "# Build EventLog with 10,000 identical traces\n",
    "event_log = EventLog([make_trace(variant, id) for id in range(10000)])\n",
    "\n",
    "sizes = range(50, 501, 50)\n",
    "samples_per_size = 200\n",
    "random_state = 1\n",
    "samples = sample_random_traces_with_replacement(event_log, sizes, samples_per_size, random_state)\n",
    "adapters = [\"vidgof_sample\"]\n",
    "df_metrics = compute_metrics_for_samples(samples, adapters)\n",
    "sample_metrics_per_log['strict_monotone_growth'] = df_metrics\n",
    "print(df_metrics)\n",
    "\n",
    "# plot Number of events\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "df_metrics.boxplot(\n",
    "    column=\"Number of Events\",\n",
    "    by=\"window_size\",\n",
    "    ax=ax,\n",
    "    grid=False\n",
    ")\n",
    "ax.set_xlabel(\"Window Size\")\n",
    "ax.set_ylabel(\"Number of Events\")\n",
    "ax.set_title(\"Number of Events vs Window Size (Single Variant Log)\")\n",
    "plt.suptitle(\"\")  # remove automatic title from pandas\n",
    "\n",
    "# Ensure output directory exists\n",
    "out_path = Path(\"results/correlations/problematization/p1.png\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0727f7dc",
   "metadata": {},
   "source": [
    "## P2 Infinite Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe23775",
   "metadata": {},
   "outputs": [],
   "source": [
    "## P2 Infinite support\n",
    "# Looped models cause unbounded number of distinct variants\n",
    "\n",
    "# Path to the BPMN file exported from BPMN.io (A->B->C with self-loop on B)\n",
    "bpmn_path = r\"data\\synthetic\\simple_loop\\simple_loop.bpmn\"\n",
    "# Import BPMN\n",
    "bpmn_graph = bpmn_importer.apply(bpmn_path)\n",
    "\n",
    "# Convert BPMN -> (Petri net, initial marking, final marking)\n",
    "net, im, fm = bpmn_converter.apply(bpmn_graph)\n",
    "\n",
    "event_log = simulator.apply(\n",
    "    net,\n",
    "    im,\n",
    "    fm,\n",
    "    parameters = {\n",
    "        \"no_traces\": 10000,\n",
    "        \"random_seed\": 1\n",
    "    },\n",
    "    variant=simulator.Variants.BASIC_PLAYOUT,\n",
    ")\n",
    "\n",
    "# quick peek\n",
    "for i, trace in enumerate(event_log[:5], 1):\n",
    "    print(f\"Trace {i}:\", [ev[\"concept:name\"] for ev in trace])\n",
    "\n",
    "sizes = range(50, 501, 50)\n",
    "samples_per_size = 200\n",
    "random_state = 1\n",
    "samples = sample_random_traces_with_replacement(event_log, sizes, samples_per_size, random_state)\n",
    "adapters = [\"vidgof_sample\"]\n",
    "df_metrics = compute_metrics_for_samples(samples, adapters)\n",
    "sample_metrics_per_log['infinite_support'] = df_metrics\n",
    "print(df_metrics)\n",
    "\n",
    "# Boxplot Distinct traces vs Window Size\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "df_metrics.boxplot(\n",
    "    column=\"Number of Distinct Traces\",\n",
    "    by=\"window_size\",\n",
    "    ax=ax,\n",
    "    grid=False\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Window Size\")\n",
    "ax.set_ylabel(\"Number of Distinct Traces\")\n",
    "ax.set_title(\"Number of Distinct Traces vs Window Size (Looping Log)\")\n",
    "plt.suptitle(\"\")  # remove automatic title from pandas\n",
    "\n",
    "# Ensure output directory exists\n",
    "out_path = Path(\"results/correlations/problematization/p2.png\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2240a2",
   "metadata": {},
   "source": [
    "## Rare occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ead054",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_trace' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m9990\u001b[39m:\n\u001b[1;32m---> 12\u001b[0m         traces\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmake_trace\u001b[49m(frequent_variant, \u001b[38;5;28mid\u001b[39m))\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m         traces\u001b[38;5;241m.\u001b[39mappend(make_trace(once_occuring_variants[\u001b[38;5;28mid\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m9990\u001b[39m], \u001b[38;5;28mid\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'make_trace' is not defined"
     ]
    }
   ],
   "source": [
    "## P3 Rare occurrences\n",
    "# The complexity metric under-estimates rarely occurring behavior due to skewed occurrence distributions.\n",
    "\n",
    "# Create trace variants\n",
    "frequent_variant = [\"A\"]\n",
    "once_occuring_variants = [[f\"B_{i}\"] for i in range (0, 10)] # 10 variants that occur only once\n",
    "\n",
    "# Build EventLog with 10,000 traces of two variants\n",
    "traces = []\n",
    "for id in range(10000):\n",
    "    if id < 9990:\n",
    "        traces.append(make_trace(frequent_variant, id))\n",
    "    else:\n",
    "        traces.append(make_trace(once_occuring_variants[id - 9990], id))\n",
    "\n",
    "# shuffle traces (should not matter due to random sampling but just to be sure)\n",
    "random.seed(1)\n",
    "random.shuffle(traces)\n",
    "\n",
    "event_log = EventLog(traces)\n",
    "\n",
    "sizes = range(50, 501, 50)\n",
    "samples_per_size = 200\n",
    "random_state = 1\n",
    "samples = sample_random_traces_with_replacement(event_log, sizes, samples_per_size, random_state)\n",
    "adapters = [\"vidgof_sample\"]\n",
    "df_metrics = compute_metrics_for_samples(samples, adapters)\n",
    "sample_metrics_per_log['rare_occurrences'] = df_metrics\n",
    "print(df_metrics)\n",
    "\n",
    "# Boxplot Variety vs Window Size\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "df_metrics.boxplot(\n",
    "    column=\"Number of Distinct Activities\",\n",
    "    by=\"window_size\",\n",
    "    ax=ax,\n",
    "    grid=False\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Window Size\")\n",
    "ax.set_ylabel(\"Number of Distinct Activities\")\n",
    "ax.set_title(\"Number of Distinct Activities vs Window Size (Skewed Variant Log)\")\n",
    "plt.suptitle(\"\")  # remove automatic title from pandas\n",
    "\n",
    "# Ensure output directory exists\n",
    "out_path = Path(\"results/correlations/problematization/p3.png\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "out_path\n",
    "\n",
    "## P4 Variance\n",
    "# The complexity metric fluctuates at small sample sizes due to the law of small numbers. Only at higher sample window sizes, the metric becomes asymptotic.\n",
    "\n",
    "# Create a trace variant A-B-C-D-E\n",
    "variant_a = [\"A\", \"B\", \"C\", \"D\", \"E\"] # length: 5\n",
    "variant_b = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\"] # length: 10]\n",
    "\n",
    "\n",
    "# Build EventLog with 10,000 traces of two variants\n",
    "traces = []\n",
    "for id in range(10000):\n",
    "    if id % 2 == 0:\n",
    "        traces.append(make_trace(variant_a, id))\n",
    "    else:\n",
    "        traces.append(make_trace(variant_b, id))\n",
    "\n",
    "event_log = EventLog(traces)\n",
    "\n",
    "sizes = range(50, 501, 50)\n",
    "samples_per_size = 200\n",
    "random_state = 1\n",
    "samples = sample_random_traces_with_replacement(event_log, sizes, samples_per_size, random_state)\n",
    "adapters = [\"vidgof_sample\"]\n",
    "df_metrics = compute_metrics_for_samples(samples, adapters)\n",
    "sample_metrics_per_log['variance'] = df_metrics\n",
    "print(df_metrics)\n",
    "\n",
    "# plot Trace length\n",
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "df_metrics.boxplot(\n",
    "    column=\"Avg. Trace Length\",\n",
    "    by=\"window_size\",\n",
    "    ax=ax,\n",
    "    grid=False\n",
    ")\n",
    "ax.set_xlabel(\"Window Size\")\n",
    "ax.set_ylabel(\"Avg. Trace Length\")\n",
    "ax.set_title(\"Avg. Trace Length vs Window Size (Two Variant Log)\")\n",
    "plt.suptitle(\"\")  # remove automatic title from pandas\n",
    "\n",
    "# Ensure output directory exists\n",
    "out_path = Path(\"results/correlations/problematization/p4.png\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(out_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faf734c",
   "metadata": {},
   "source": [
    "## Get correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c187d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlations_for_dictionary(sample_metrics_per_log):\n",
    "    # create a correlation analysis for all measures\n",
    "    from pathlib import Path\n",
    "    import pandas as pd\n",
    "    from scipy import stats\n",
    "\n",
    "    # mapping of your dict keys to desired column names\n",
    "    rename_map = {\n",
    "        \"strict_monotone_growth\": \"P1\",\n",
    "        \"infinite_support\": \"P2\",\n",
    "        \"rare_occurrences\": \"P3\",\n",
    "        \"variance\": \"P4\",\n",
    "    }\n",
    "\n",
    "    r_results, p_results = {}, {}\n",
    "\n",
    "    for key, df in sample_metrics_per_log.items():\n",
    "        col_tag = rename_map[key]\n",
    "        r_results[col_tag] = {}\n",
    "        p_results[col_tag] = {}\n",
    "\n",
    "        for col in df.columns:\n",
    "            if col in {\"window_size\", \"sample_id\", \"Time Granularity\"}:\n",
    "                continue\n",
    "            # drop missing values pairwise\n",
    "            tmp = df[[\"window_size\", col]].dropna()\n",
    "            if len(tmp) < 2:\n",
    "                r, p = float(\"nan\"), float(\"nan\")\n",
    "            else:\n",
    "                r, p = stats.pearsonr(tmp[\"window_size\"], tmp[col])\n",
    "            r_results[col_tag][col] = r\n",
    "            p_results[col_tag][col] = p\n",
    "\n",
    "    # DataFrames: measures as index, P1..P4 as columns\n",
    "    corr_df = pd.DataFrame(r_results)\n",
    "    pval_df = pd.DataFrame(p_results).reindex(corr_df.index)\n",
    "    print(\"Correlations:\")\n",
    "    print(corr_df)\n",
    "    print()\n",
    "    print(\"P-values:\")\n",
    "    print(pval_df)\n",
    "\n",
    "    return corr_df, pval_df\n",
    "\n",
    "corr_df, pval_df = get_correlations_for_dictionary(df_metrics)\n",
    "\n",
    "# Save\n",
    "out_dir = Path(\"results/correlations/problematization\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "corr_df.to_csv(out_dir / \"correlations_r.csv\")\n",
    "pval_df.to_csv(out_dir / \"correlations_p.csv\")\n",
    "\n",
    "\n",
    "# Create Latex output\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def _stars(p: float) -> str:\n",
    "    if pd.isna(p):\n",
    "        return \"\"\n",
    "    if p < 0.001:\n",
    "        return \"***\"\n",
    "    if p < 0.01:\n",
    "        return \"**\"\n",
    "    if p < 0.05:\n",
    "        return \"*\"\n",
    "    return \"\"\n",
    "\n",
    "def corr_p_to_latex_stars(corr_df: pd.DataFrame, pval_df: pd.DataFrame, out_path: Path) -> None:\n",
    "    # keep P1..P4 order if present\n",
    "    cols = [c for c in [\"P1\", \"P2\", \"P3\", \"P4\"] if c in corr_df.columns]\n",
    "    corr = corr_df[cols].copy()\n",
    "    pval = pval_df[cols].copy()\n",
    "    corr, pval = corr.align(pval, join=\"outer\", axis=0)\n",
    "\n",
    "    # Build display DataFrame with \"+/-r***\" format\n",
    "    disp = corr.copy().astype(object)\n",
    "    for c in cols:\n",
    "        out_col = []\n",
    "        for r, p in zip(corr[c], pval[c]):\n",
    "            if pd.isna(r):\n",
    "                out_col.append(\"\")\n",
    "            else:\n",
    "                out_col.append(f\"{r:+.2f}{_stars(p)}\")\n",
    "        disp[c] = out_col\n",
    "\n",
    "    latex_body = disp.to_latex(\n",
    "        escape=True,\n",
    "        na_rep=\"\",\n",
    "        index=True,\n",
    "        column_format=\"l\" + \"c\"*len(cols),\n",
    "        bold_rows=False\n",
    "    )\n",
    "\n",
    "    wrapped = rf\"\"\"\n",
    "    \\begin{{table}}[htbp]\n",
    "    \\centering\n",
    "    \\caption{{Pearson correlation ($r$) between window size and each measure.}}\n",
    "    \\scriptsize\n",
    "    \\setlength{{\\tabcolsep}}{{6pt}}\n",
    "    \\renewcommand{{\\arraystretch}}{{1.15}}\n",
    "    {latex_body}\n",
    "    \\vspace{{2pt}}\n",
    "    \\begin{{minipage}}{{0.95\\linewidth}}\\footnotesize\n",
    "    Stars denote significance: $^*p<0.05$, $^{{**}}p<0.01$, $^{{***}}p<0.001$.\n",
    "    \\end{{minipage}}\n",
    "    \\end{{table}}\n",
    "    \"\"\"\n",
    "\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(wrapped)\n",
    "\n",
    "corr_p_to_latex_stars(corr_df, pval_df, Path(\"results/correlations/problematization/correlations_table.tex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14784d64",
   "metadata": {},
   "source": [
    "## Fix problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df07d5bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sample_metrics_per_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 40\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fixed_metrics_per_log\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m## Expectation 1: convergence\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m fixed_metrics_per_log \u001b[38;5;241m=\u001b[39m apply_fixes_all_metrics_dicts(\u001b[43msample_metrics_per_log\u001b[49m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# get new correlations\u001b[39;00m\n\u001b[0;32m     43\u001b[0m corr_df, pval_df \u001b[38;5;241m=\u001b[39m get_correlations_for_dictionary(fixed_metrics_per_log)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample_metrics_per_log' is not defined"
     ]
    }
   ],
   "source": [
    "def fix_p1(metrics_dict):\n",
    "    fixed_metrics_dict = metrics_dict.copy()\n",
    "    fixed_metrics_dict['Number of Events'] = metrics_dict['Number of Events'] / metrics_dict['Number of Traces'] # normalize by number of traces to get avg trace length\n",
    "    fixed_metrics_dict['Number of Traces'] = None # do not report number of traces as this will always correlate with trace count based sample sizes (alternatively, devide by number of traces which would lead to constant 1)\n",
    "    fixed_metrics_dict['Percentage of Distinct Traces'] = metrics_dict['Percentage of Distinct Traces'] * metrics_dict['Number of Traces'] # this gives the same as number of distinct traces\n",
    "    fixed_metrics_dict['Deviation from Random'] = (\n",
    "        metrics_dict['Deviation from Random']\n",
    "        / np.sqrt(1 - (1 / metrics_dict['Number of Traces']))\n",
    "    ) # devision by the worst case scenario (single activity transition)\n",
    "    fixed_metrics_dict['Lempel-Ziv Complexity'] = (\n",
    "        metrics_dict['Lempel-Ziv Complexity']\n",
    "        / (\n",
    "            metrics_dict['Number of Traces']\n",
    "            / (\n",
    "                np.log(metrics_dict['Number of Distinct Activities'])\n",
    "                / np.log(metrics_dict['Number of Traces'])\n",
    "            )\n",
    "        )\n",
    "    ) #  see Kaspar and Schuster 1987\n",
    "    fixed_metrics_dict['Number of Ties in Paths to Goal'] = metrics_dict['Number of Ties in Paths to Goal'] / metrics_dict['Number of Traces'] # TODO better approach desired\n",
    "    fixed_metrics_dict['Variant Entropy'] = metrics_dict['Variant Entropy'] / metrics_dict['Number of Traces'] # TODO better approach desired\n",
    "    fixed_metrics_dict['Normalized Variant Entropy'] = metrics_dict['Normalized Variant Entropy'] / metrics_dict['Number of Traces'] # TODO better approach desired\n",
    "    fixed_metrics_dict['Trace Entropy'] = metrics_dict['Trace Entropy'] / metrics_dict['Number of Traces'] # TODO better approach desired\n",
    "    fixed_metrics_dict['Normalized Trace Entropy'] = metrics_dict['Normalized Trace Entropy'] / metrics_dict['Number of Traces'] # TODO better approach desired\n",
    "\n",
    "    return fixed_metrics_dict\n",
    "\n",
    "def apply_fixes_all_metrics_dicts(metrics_dicts_per_log, problems_to_fix=['p1']):\n",
    "    fixed_metrics_per_log = {}\n",
    "    for log_name in metrics_dicts_per_log:\n",
    "        if 'p1' in problems_to_fix:\n",
    "            # fix p1\n",
    "            fixed_metrics_per_log[log_name] = fix_p1(metrics_dicts_per_log[log_name])\n",
    "        # TODO fix further problems\n",
    "    \n",
    "    return fixed_metrics_per_log\n",
    "\n",
    "## Expectation 1: convergence\n",
    "\n",
    "fixed_metrics_per_log = apply_fixes_all_metrics_dicts(sample_metrics_per_log)\n",
    "\n",
    "# get new correlations\n",
    "corr_df, pval_df = get_correlations_for_dictionary(fixed_metrics_per_log)\n",
    "\n",
    "# Save\n",
    "out_dir = Path(\"results/correlations/problematization\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "corr_df.to_csv(out_dir / \"correlations_r_p1_fixed.csv\")\n",
    "pval_df.to_csv(out_dir / \"correlations_p_p1_fixed.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58491fa2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drifts-and-complexity",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
